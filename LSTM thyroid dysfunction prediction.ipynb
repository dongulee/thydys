{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'UTF-8'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from os import listdir\n",
    "from itertools import combinations\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import subprocess\n",
    "import tensorflow as tf\n",
    "import utils as utl\n",
    "#from collections import Counter\n",
    "\n",
    "import sys\n",
    "sys.stdin.encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load wearable sensor-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = 'data/'\n",
    "remove_files = ('.ipynb_checkpoints', 'code_tester.ipynb','.idea', '.cache')\n",
    "\n",
    "# sensor data files\n",
    "datalist = listdir(base_dir + 'sensors') \n",
    "datalist = [x for x in datalist if x not in remove_files] #포함시키지 않을 경로명 제외하고 리스트 생성\n",
    "#print(datalist)\n",
    "\n",
    "pid_list = [x.split('_')[0] for x in datalist]\n",
    "pid_list = list(set(pid_list))\n",
    "pid_list.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PList = []\n",
    "for pid in pid_list:\n",
    "\n",
    "    activity = '_activity_intraday.csv'\n",
    "    HR = '_HR_intraday.csv'\n",
    "    PList.append({'pid': pid[4:6], 'HR': pid+HR, 'act': pid+activity})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load medical diagnosis data (Blood test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial#</th>\n",
       "      <th>Group</th>\n",
       "      <th>DOB</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>visit</th>\n",
       "      <th>Ht</th>\n",
       "      <th>Lab_date</th>\n",
       "      <th>freeT4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1973-01-03</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2016-11-10</td>\n",
       "      <td>3.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1973-01-03</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2016-12-16</td>\n",
       "      <td>1.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1973-01-03</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2017-01-06</td>\n",
       "      <td>1.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1973-01-03</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2017-02-03</td>\n",
       "      <td>1.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1976-12-11</td>\n",
       "      <td>39</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>166.0</td>\n",
       "      <td>2016-11-18</td>\n",
       "      <td>1.67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Serial#  Group         DOB  age  gender  visit     Ht    Lab_date  freeT4\n",
       "0        1      1  1973-01-03   43       2      1  162.0  2016-11-10    3.43\n",
       "1        1      1  1973-01-03   43       2      2  162.0  2016-12-16    1.80\n",
       "2        1      1  1973-01-03   43       2      3  162.0  2017-01-06    1.61\n",
       "3        1      1  1973-01-03   43       2      4  162.0  2017-02-03    1.49\n",
       "4        2      1  1976-12-11   39       2      1  166.0  2016-11-18    1.67"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diagnosis = pd.read_csv(base_dir + 'label/diagnosis.csv')\n",
    "diagnosis.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing\n",
    "\n",
    "creating each input as \n",
    "* pre 5-day Heart Rate sequence by second\n",
    "* pre 5-day Activity sequence by second\n",
    "* interpolation to eliminate data loss\n",
    "* age, gender, Height\n",
    "\n",
    "\n",
    "## Dataset Class: hr_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Helper functions to trim sequence data using lab date (blood test date)\n",
    "5 days * 24 hours * 60 mins = 7200 sequences ordered by timestamp\n",
    "HRseq = [66, 67, 76, 64, 90, 114, ...]\n",
    "Actseq = [0.667, 0.667, ..., 3.252, 6.554, ...] # calories\n",
    "'''\n",
    "\n",
    "#for x in range(1,2): # embedded number of id\n",
    "def getDiagByPid(diagnosis, pid):\n",
    "    ret = []\n",
    "    idx = diagnosis['Serial#']==pid\n",
    "    selected = diagnosis[:][idx]\n",
    "    for index, row in selected.iterrows():\n",
    "        item = {}\n",
    "        for key in row.keys():\n",
    "            #print(key)\n",
    "            item[key] = row[key]\n",
    "        ret.append(item)\n",
    "    return ret    \n",
    "def getSeqByDate(seq, lab_date):\n",
    "    # (Lab date - 5 DAY) 보다 sequence date 기록이 적은 경우, labdate 후 5일 seq 반환\n",
    "    \n",
    "    \n",
    "    end_date = pd.Timestamp(lab_date)\n",
    "    start_date = end_date - pd.Timedelta('10 day')\n",
    "    \n",
    "    try:\n",
    "        seq_tmp = seq[start_date:end_date]\n",
    "    except:\n",
    "        return 'null', None\n",
    "    \n",
    "    if len(seq_tmp) == 0:\n",
    "        start_date = end_date\n",
    "        end_date = start_date + pd.Timedelta('10 day')\n",
    "        seq_tmp = seq[start_date:end_date]\n",
    "        if len(seq_tmp) == 0:\n",
    "            return 'null', None\n",
    "        else:\n",
    "            return 'before', seq_tmp\n",
    "    else:\n",
    "        return 'after', seq_tmp\n",
    "    \n",
    "def getSeqByPid(basedir, seqlist, pid):\n",
    "    print(pid)\n",
    "    '''\n",
    "    Return HR, Activity Sequences by Pid\n",
    "    ({'Timestamp': timestamp, 'Value': value})\n",
    "    '''\n",
    "    #find HR file name\n",
    "    candidate = [x for x in seqlist if x['pid']==pid]\n",
    "        \n",
    "    hrfile = basedir + 'sensors/' + candidate[0]['HR']\n",
    "    actfile = basedir + 'sensors/' + candidate[0]['act']\n",
    "    \n",
    "    # HR: 5 seconds -> 1 minute average aggregation\n",
    "    hrseq = pd.read_csv(hrfile, header=0, parse_dates=['HEART RATE DATE/TIME'], index_col = 'HEART RATE DATE/TIME', usecols = ['HEART RATE DATE/TIME', 'VALUE'])\n",
    "    hrseq = hrseq.resample('1T').mean().sort_index()\n",
    "    actseq = pd.read_csv(actfile, header=0, quotechar ='\\\"', parse_dates=[\"ACTIVITY DATE/TIME\"],index_col=\"ACTIVITY DATE/TIME\", usecols=[\"ACTIVITY DATE/TIME\", \"CALORIES\"])\n",
    "    actseq = actseq.sort_index()\n",
    "    return hrseq, actseq\n",
    "    \n",
    "    \n",
    "class hr_data:\n",
    "    def __init__(self, seq, diagnosis):\n",
    "        self.seq_list = seq\n",
    "        self.diag = diagnosis\n",
    "        \n",
    "        # pid_list: 1, 2, 3, 5, 6, 7, ...\n",
    "        pid_list = [x['pid'] for x in self.seq_list]\n",
    "        \n",
    "        self.dataset = []\n",
    "        # 환자별로 시퀀스 생성\n",
    "        for pid in pid_list:\n",
    "            pid_int = int(pid)\n",
    "            for medical_record in getDiagByPid(self.diag, pid_int):\n",
    "                HR_pd, ACT_pd = getSeqByPid('data/', self.seq_list, pid)\n",
    "                \n",
    "                # Input Data\n",
    "                date = medical_record['Lab_date']\n",
    "                age = medical_record['age']\n",
    "                gender = medical_record['gender']\n",
    "                height = medical_record['Ht']\n",
    "                s_type, HRseq = getSeqByDate(HR_pd, date)\n",
    "                s_type2, ACTseq = getSeqByDate(ACT_pd, date)\n",
    "                \n",
    "                if s_type != s_type2 or s_type == 'null' or s_type2 == 'null':\n",
    "                    continue\n",
    "                \n",
    "                # Label\n",
    "                freeT4 = medical_record['freeT4']\n",
    "                categorical = [age, gender, height, s_type]\n",
    "                \n",
    "                x1 = HRseq[:-1]\n",
    "                x2 = ACTseq[:-1]\n",
    "                if len(x1) == 7200 and len(x2) == 7200:\n",
    "                    self.dataset.append({'categorical':categorical, 'HR': x1, 'ACT': x2, 'freeT4':freeT4})\n",
    "                else:\n",
    "                    continue\n",
    "    def fillna(self):\n",
    "        for record in self.dataset:\n",
    "            record['HR'] = record['HR'].fillna(0)\n",
    "            record['ACT'] = record['ACT'].fillna(0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01\n",
      "01\n",
      "01\n",
      "01\n",
      "02\n",
      "02\n",
      "02\n",
      "04\n",
      "04\n",
      "04\n",
      "04\n",
      "05\n",
      "05\n",
      "05\n",
      "05\n",
      "06\n",
      "06\n",
      "07\n",
      "07\n",
      "07\n",
      "07\n",
      "07\n",
      "08\n",
      "08\n",
      "08\n",
      "09\n",
      "09\n",
      "09\n",
      "09\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "17\n",
      "17\n",
      "17\n",
      "18\n",
      "18\n",
      "18\n",
      "18\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "22\n",
      "22\n",
      "22\n",
      "22\n",
      "23\n",
      "23\n",
      "23\n",
      "23\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "26\n",
      "26\n",
      "26\n",
      "27\n",
      "27\n",
      "27\n",
      "27\n",
      "28\n",
      "28\n",
      "28\n",
      "28\n",
      "29\n",
      "29\n",
      "29\n",
      "29\n",
      "30\n",
      "30\n",
      "30\n",
      "31\n",
      "31\n",
      "31\n",
      "32\n",
      "32\n",
      "32\n",
      "33\n",
      "33\n",
      "33\n",
      "34\n",
      "34\n",
      "34\n",
      "35\n",
      "35\n",
      "35\n",
      "36\n",
      "36\n",
      "36\n",
      "37\n",
      "37\n",
      "37\n",
      "38\n",
      "38\n",
      "38\n",
      "39\n",
      "39\n",
      "39\n",
      "40\n",
      "40\n",
      "40\n"
     ]
    }
   ],
   "source": [
    "# Dataset instance\n",
    "\n",
    "dataset = hr_data(PList, diagnosis)\n",
    "dataset.fillna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input\n",
    "\n",
    "<img src=\"img/input.png\" style=\"height:80px\">\n",
    "\n",
    "Save this data into files \"X.dat, Y.dat\" to load fast in training step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-b72136212027>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'HR'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ACT'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m96\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m14400\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'freeT4'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "X = [ (x['HR'].values, x['ACT'].values) for x in dataset.dataset]\n",
    "X = np.array(X).reshape([96, 14400])\n",
    "Y = [ x['freeT4'] for x in dataset.dataset]\n",
    "Y = np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.tofile('X.dat')\n",
    "Y.tofile('Y.dat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test to load pre-processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.fromfile('X.dat', dtype=float).reshape([96,14400])\n",
    "Y = np.fromfile('Y.dat', dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Set Size\n",
      "Train set: \t\t(76, 14400) \n",
      "Validation set: \t(10, 14400) \n",
      "Test set: \t\t(10, 14400)\n"
     ]
    }
   ],
   "source": [
    "train_x, val_x, test_x, train_y, val_y, test_y = utl.train_val_test_split(X, Y, split_frac=0.80)\n",
    "print(\"Data Set Size\")\n",
    "print(\"Train set: \\t\\t{}\".format(train_x.shape), \n",
    "      \"\\nValidation set: \\t{}\".format(val_x.shape),\n",
    "      \"\\nTest set: \\t\\t{}\".format(test_x.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
