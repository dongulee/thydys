{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from os import listdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(141, 9)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diagnosis = pd.read_csv('data/label/diagnosis.csv')\n",
    "diagnosis.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GDAT36_HR_intraday.csv\n",
      "(533001, 3)\n",
      "GDAT39_activity_intraday.csv\n",
      "(86400, 6)\n",
      "GDAT10_HR_intraday.csv\n",
      "(1463893, 3)\n",
      "GDAT29_HR_intraday.csv\n",
      "(954801, 3)\n",
      "GDAT15_activity_intraday.csv\n",
      "(204480, 6)\n",
      "GDAT20_activity_intraday.csv\n",
      "(201600, 6)\n",
      "GDAT08_HR_intraday.csv\n",
      "(696698, 3)\n",
      "GDAT17_activity_intraday.csv\n",
      "(141120, 6)\n",
      "GDAT10_activity_intraday.csv\n",
      "(252000, 6)\n",
      "GDAT13_activity_intraday.csv\n",
      "(213120, 6)\n",
      "GDAT01_activity_intraday.csv\n",
      "(123840, 6)\n",
      "GDAT18_HR_intraday.csv\n",
      "(1723647, 3)\n",
      "GDAT30_activity_intraday.csv\n",
      "(142560, 6)\n",
      "GDAT14_activity_intraday.csv\n",
      "(213120, 6)\n",
      "GDAT39_HR_intraday.csv\n",
      "(539122, 3)\n",
      "GDAT24_HR_intraday.csv\n",
      "(1186280, 3)\n",
      "GDAT11_activity_intraday.csv\n",
      "(237600, 6)\n",
      "GDAT21_HR_intraday.csv\n",
      "(938843, 3)\n",
      "GDAT06_activity_intraday.csv\n",
      "(200160, 6)\n",
      "GDAT23_HR_intraday.csv\n",
      "(369770, 3)\n",
      "GDAT33_HR_intraday.csv\n",
      "(445247, 3)\n",
      "GDAT07_activity_intraday.csv\n",
      "(306720, 6)\n",
      "GDAT33_activity_intraday.csv\n",
      "(96480, 6)\n",
      "GDAT26_HR_intraday.csv\n",
      "(866373, 3)\n",
      "GDAT27_HR_intraday.csv\n",
      "(1849783, 3)\n",
      "GDAT37_activity_intraday.csv\n",
      "(93600, 6)\n",
      "GDAT16_HR_intraday.csv\n",
      "(560327, 3)\n",
      "GDAT37_HR_intraday.csv\n",
      "(551841, 3)\n",
      "GDAT15_HR_intraday.csv\n",
      "(1132900, 3)\n",
      "GDAT34_activity_intraday.csv\n",
      "(92160, 6)\n",
      "GDAT36_activity_intraday.csv\n",
      "(93600, 6)\n",
      "GDAT11_HR_intraday.csv\n",
      "(516153, 3)\n",
      "GDAT28_activity_intraday.csv\n",
      "(197280, 6)\n",
      "GDAT34_HR_intraday.csv\n",
      "(732416, 3)\n",
      "GDAT21_activity_intraday.csv\n",
      "(201600, 6)\n",
      "GDAT20_HR_intraday.csv\n",
      "(603920, 3)\n",
      "GDAT19_activity_intraday.csv\n",
      "(181440, 6)\n",
      "GDAT23_activity_intraday.csv\n",
      "(181440, 6)\n",
      "GDAT35_activity_intraday.csv\n",
      "(105120, 6)\n",
      "GDAT40_activity_intraday.csv\n",
      "(92160, 6)\n",
      "GDAT07_HR_intraday.csv\n",
      "(1674424, 3)\n",
      "GDAT38_activity_intraday.csv\n",
      "(87840, 6)\n",
      "GDAT24_activity_intraday.csv\n",
      "(199598, 6)\n",
      "GDAT09_activity_intraday.csv\n",
      "(132480, 6)\n",
      "GDAT16_activity_intraday.csv\n",
      "(181440, 6)\n",
      "GDAT22_activity_intraday.csv\n",
      "(201600, 6)\n",
      "GDAT32_activity_intraday.csv\n",
      "(96480, 6)\n",
      "GDAT29_activity_intraday.csv\n",
      "(141120, 6)\n",
      "GDAT02_HR_intraday.csv\n",
      "(704212, 2)\n",
      "GDAT04_activity_intraday.csv\n",
      "(122400, 6)\n",
      "GDAT40_HR_intraday.csv\n",
      "(543057, 3)\n",
      "GDAT18_activity_intraday.csv\n",
      "(181440, 6)\n",
      "GDAT26_activity_intraday.csv\n",
      "(181440, 6)\n",
      "GDAT28_HR_intraday.csv\n",
      "(1006147, 3)\n",
      "GDAT25_HR_intraday.csv\n",
      "(2205752, 3)\n",
      "GDAT04_HR_intraday.csv\n",
      "(301542, 2)\n",
      "GDAT30_HR_intraday.csv\n",
      "(771946, 3)\n",
      "GDAT19_HR_intraday.csv\n",
      "(271292, 3)\n",
      "GDAT22_HR_intraday.csv\n",
      "(694993, 3)\n",
      "GDAT25_activity_intraday.csv\n",
      "(161280, 6)\n",
      "GDAT13_HR_intraday.csv\n",
      "(981085, 3)\n",
      "GDAT01_HR_intraday.csv\n",
      "(661177, 2)\n",
      "GDAT06_HR_intraday.csv\n",
      "(1578566, 3)\n",
      "GDAT09_HR_intraday.csv\n",
      "(751688, 3)\n",
      "GDAT27_activity_intraday.csv\n",
      "(181440, 6)\n",
      "GDAT17_HR_intraday.csv\n",
      "(370876, 2)\n",
      "GDAT35_HR_intraday.csv\n",
      "(690292, 3)\n",
      "GDAT14_HR_intraday.csv\n",
      "(1124692, 3)\n",
      "GDAT05_HR_intraday.csv\n",
      "(575745, 2)\n",
      "GDAT02_activity_intraday.csv\n",
      "(129600, 6)\n",
      "GDAT08_activity_intraday.csv\n",
      "(112320, 6)\n",
      "GDAT31_activity_intraday.csv\n",
      "(99360, 6)\n",
      "GDAT32_HR_intraday.csv\n",
      "(580046, 3)\n",
      "GDAT05_activity_intraday.csv\n",
      "(118080, 6)\n",
      "GDAT38_HR_intraday.csv\n",
      "(514694, 3)\n",
      "GDAT31_HR_intraday.csv\n",
      "(1897107, 3)\n"
     ]
    }
   ],
   "source": [
    "remove_files = ('.ipynb_checkpoints', 'code_tester.ipynb','.idea', '.cache')\n",
    "datalist = listdir('data/sensors') #같은 경로내 존재하는 폴더이름을 리스트화\n",
    "datalist = [x for x in datalist if x not in remove_files] #포함시키지 않을 경로명 제외하고 리스트 생성\n",
    "for f in datalist:\n",
    "    print(f)\n",
    "    df = pd.read_csv('data/sensors/' + f)\n",
    "    print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from itertools import combinations\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import subprocessf\n",
    "import tensorflow as tf\n",
    "import utils as utl\n",
    "#from collections import Counter\n",
    "\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "'''\n",
    "Helper functions to trim sequence data using lab date (blood test date)\n",
    "5 days * 24 hours * 60 mins = 7200 sequences ordered by timestamp\n",
    "HRseq = [66, 67, 76, 64, 90, 114, ...]\n",
    "Actseq = [0.667, 0.667, ..., 3.252, 6.554, ...] # calories\n",
    "'''\n",
    "\n",
    "#for x in range(1,2): # embedded number of id\n",
    "def getDiagByPid(diagnosis, pid):\n",
    "    ret = []\n",
    "    idx = diagnosis['Serial#']==pid\n",
    "    selected = diagnosis[:][idx]\n",
    "    for index, row in selected.iterrows():\n",
    "        item = {}\n",
    "        for key in row.keys():\n",
    "            #print(key)\n",
    "            item[key] = row[key]\n",
    "        ret.append(item)\n",
    "    return ret\n",
    "\n",
    "def getSeqByDate(seq, lab_date):\n",
    "    # (Lab date - 5 DAY) 보다 sequence date 기록이 적은 경우, labdate 후 5일 seq 반환\n",
    "    \n",
    "    end_date = pd.Timestamp(lab_date)\n",
    "    start_date = end_date - pd.Timedelta('5 day')\n",
    "    \n",
    "    try:\n",
    "        seq_tmp = seq[start_date:end_date]\n",
    "    except:\n",
    "        return 'null', None\n",
    "    \n",
    "    if len(seq_tmp) == 0:\n",
    "        start_date = end_date\n",
    "        end_date = start_date + pd.Timedelta('5 day')\n",
    "        seq_tmp = seq[start_date:end_date]\n",
    "        if len(seq_tmp) == 0:\n",
    "            return 'null', None\n",
    "        else:\n",
    "            return 'before', seq_tmp\n",
    "    else:\n",
    "        return 'after', seq_tmp\n",
    "    \n",
    "def getSeqByPid(basedir, seqlist, pid):\n",
    "    print(pid)\n",
    "    '''\n",
    "    Return HR, Activity Sequences by Pid\n",
    "    ({'Timestamp': timestamp, 'Value': value})\n",
    "    '''\n",
    "    #find HR file name\n",
    "    candidate = [x for x in seqlist if x['pid']==pid]\n",
    "        \n",
    "    hrfile = basedir + '/sensors/' + candidate[0]['HR']\n",
    "    actfile = basedir + '/sensors/' + candidate[0]['act']\n",
    "    \n",
    "    # HR: 5 seconds -> 1 minute average aggregation\n",
    "    hrseq = pd.read_csv(hrfile, header=0, parse_dates=['HEART RATE DATE/TIME'], index_col = 'HEART RATE DATE/TIME', usecols = ['HEART RATE DATE/TIME', 'VALUE'])\n",
    "    hrseq = hrseq.resample('15T').mean().sort_index()\n",
    "    actseq = pd.read_csv(actfile, header=0, parse_dates=[\"ACTIVITY DATE/TIME\"],index_col=\"ACTIVITY DATE/TIME\", usecols=[\"ACTIVITY DATE/TIME\", \"CALORIES\"])\n",
    "    actseq = actseq.resample('15T').mean().sort_index()\n",
    "    return hrseq, actseq\n",
    "    \n",
    "    \n",
    "class hr_data:\n",
    "    def __init__(self, seq, diagnosis):\n",
    "        self.seq_list = seq\n",
    "        self.diag = diagnosis\n",
    "        \n",
    "        # pid_list: 1, 2, 3, 5, 6, 7, ...\n",
    "        pid_list = [x['pid'] for x in self.seq_list]\n",
    "        \n",
    "        self.dataset = []\n",
    "        # 환자별로 시퀀스 생성\n",
    "        for pid in pid_list:\n",
    "            pid_int = int(pid)\n",
    "            for medical_record in getDiagByPid(self.diag, pid_int):\n",
    "                HR_pd, ACT_pd = getSeqByPid('data', self.seq_list, pid)\n",
    "                \n",
    "                # Input Data\n",
    "                date = medical_record['Lab_date']\n",
    "                age = medical_record['age']\n",
    "                gender = medical_record['gender']\n",
    "                height = medical_record['Ht']\n",
    "                s_type, HRseq = getSeqByDate(HR_pd, date)\n",
    "                s_type2, ACTseq = getSeqByDate(ACT_pd, date)\n",
    "                \n",
    "                if s_type != s_type2 or s_type == 'null' or s_type2 == 'null':\n",
    "                    continue\n",
    "                \n",
    "                # Label\n",
    "                freeT4 = medical_record['freeT4']\n",
    "                categorical = [age, gender, height, s_type]\n",
    "                \n",
    "                x1 = HRseq[:-1]\n",
    "                x2 = ACTseq[:-1]\n",
    "                if len(x1) == 480 and len(x2) == 480:\n",
    "                    self.dataset.append({'categorical':categorical, 'HR': x1, 'ACT': x2, 'freeT4':freeT4})\n",
    "                else:\n",
    "                    continue\n",
    "    def fillna(self):\n",
    "        for record in self.dataset:\n",
    "            record['HR'] = record['HR'].fillna(0)\n",
    "            record['ACT'] = record['ACT'].fillna(0)\n",
    "\n",
    "def main():\n",
    "    if (len(sys.argv) <= 1):\n",
    "        print (\"prep_data.py -h or --help to get guideline of input options\")\n",
    "        exit()\n",
    "        \n",
    "    use = \"Usage: %prog [options] filename\"\n",
    "    parser = OptionParser(usage = use)\n",
    "    parser.add_option(\"-t\", \"--input-type\", dest=\"input_type\", default='raw', action=\"store\", type=\"string\", help=\"raw | ckpt\")\n",
    "    parser.add_option(\"-d\", \"--input-dir\", dest=\"input_dir\", default='data', action=\"store\", type=\"string\", help=\"in case of raw, inputdir should have \\'sensor\\' and \\'label\\' sub-directories\")\n",
    "    parser.add_option(\"-s\", \"--sample-rate\", dest=\"sample_rate\", default='1T', action=\"store\", type=\"string\", help=\"1T | 5T | 15T | 30T , ...\")\n",
    "    parser.add_option(\"-o\", \"--output-dir\", dest=\"output_dir\", default='data/default_ckpt', action=\"store\", type=\"string\", help=\"path of the directory which will contain ckpt data\")\n",
    "\n",
    "    #TODO: argument exception handling block\n",
    "    \n",
    "    ###\n",
    "\n",
    "    sample_rate = options.sample_rate\n",
    "    input_type = options.input_type\n",
    "    base_dir = options.input_dir\n",
    "    output_dir = options.output_dir\n",
    "\n",
    "    timesteps = 24*60*5/sample_rate\n",
    "\n",
    "\n",
    "    if input_type == \"raw\":\n",
    "        # sensor data files\n",
    "        datalist = listdir(base_dir + 'sensors') \n",
    "        datalist = [x for x in datalist if x not in remove_files] #포함시키지 않을 경로명 제외하고 리스트 생성\n",
    "        #print(datalist)\n",
    "\n",
    "        pid_list = [x.split('_')[0] for x in datalist]\n",
    "        pid_list = list(set(pid_list))\n",
    "        pid_list.sort()\n",
    "        PList = []\n",
    "        for pid in pid_list:\n",
    "\n",
    "            activity = '_activity_intraday.csv'\n",
    "            HR = '_HR_intraday.csv'\n",
    "            PList.append({'pid': pid[4:6], 'HR': pid+HR, 'act': pid+activity})\n",
    "        \n",
    "        # FIXME: patient 28 has an error\n",
    "        PList.remove({'pid': '28',\n",
    "          'HR': 'GDAT28_HR_intraday.csv',\n",
    "          'act': 'GDAT28_activity_intraday.csv'})\n",
    "        diagnosis = pd.read_csv(base_dir + 'label/diagnosis.csv')\n",
    "        \n",
    "        # Load raw sequence data into hr_data class\n",
    "        dataset = hr_data(PList, diagnosis, sample_rate)\n",
    "        dataset.fillna()\n",
    "        X = [ (x['HR'].values, x['ACT'].values) for x in dataset.dataset]\n",
    "        X = np.array(X, dtype=float)\n",
    "\n",
    "        # FIXME: hardcoded input component '2'\n",
    "        X = X.reshape([len(X),timesteps*2]) \n",
    "        Y = [ x['freeT4'] for x in dataset.dataset]\n",
    "        Y = np.array(Y, dtype = float)\n",
    "\n",
    "        X.tofile(output_dir + '/' + 'X_'+ timesteps +'.dat')\n",
    "        Y.tofile(output_dir + '/' + 'Y_'+ timesteps +'.dat')\n",
    "\n",
    "    elif options.input_type == \"ckpt\":\n",
    "        pass\n",
    "    else:\n",
    "        print(\"-- input-type={0}: input type is wrong\".format(options.input_type))\n",
    "        exit()\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "    \n",
    "            \n",
    "if __name__ == \"__main__\":\n",
    "    sample_rate = argv[1]\n",
    "    main(sys.argv[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
